---
title: "Overview"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Overview and Workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(cycleR)
library(tidyverse)
```

# Introduction

\[welcoming introduction\]

The general sequence of data flow is as follows:

1.  Import the raw ride data

2.  Separate the station information from the ride information

3.  Make station dictionary?

4.  Clean member info?

5.  transform to origin-destination?

# 

# Import Raw Ride Data

We'll start by saving the path to the top folder of the raw data.

```{r}
# data path
data <- "/Volumes/Al-Hakem-II/Datasets/bks/raw"
```

Now let's import the data for all of a single year. The function `import_rides()` does a few things for us. It finds the files we want, harmonizes variable names, and appends them in a single tibble object.

First, it imports all of the `.csv` files in a single directory. We can optionally have it import only certain files within the declared directory that match a regex expression with `file_pattern`. Once it finds the files we want, imports each and ensures that each variable is named appropriately. Then, it appends all of them in a single tibble.

But we may not know the names of the columns in the raw data. Also, the names may change over time. Let's use the helper function `view_colnames()` before importing to help us.

## Check Column Names

The helper function `view_colnames()` was designed to be used right before `import_rides()` . Note that it carries many of the same arguments. Let's try it.

```{r}
colnames <- view_colnames(eval_directory = data, check_names = TRUE)
colnames
```

We see that the returned object `colnames` is a data.frame that lists all unique variable names under `colnames$column_name` and the storage type for each file in the directory. If a variable doesn't exist in one of the files, the appropriate `df_n` lists that variable as `NA`.

Based on the result from `view_colnames()` let's come up with a character vector of column names that will work for all data.frames

```{r}
raw_rename <- c(
  "bikeno" = "Bike.number",
  "duration" = "Duration",
  "enddt" = "End.date",
  "end" = "End.station" ,
  "endno" = "End.station.number" , 
  "endno" = "end_station_id",
  "end" = "end_station_name", 
  "enddt" = "ended_at",
  "member" =  "Member.type",        
  "member" = "member_casual",
  "startdt" = "Start.date",          
  "start" = "Start.station",
  "startno" = "Start.station.number", 
  "startno" = "start_station_id",   
  "start" =  "start_station_name",
  "startdt" = "started_at")
```

## Import Ride Data

Now we're ready to import the raw ride data. For this vignette, let's only import the first 500 rides of each file for speed.

```{r}
rides <- import_rides(eval_directory = data, rename_cols = raw_rename, nrows = 500)

head(rides)
```

## Import Station Data

But the ride-level data is only part of the story. We also want to keep track of where each station is so we can later incorporate weather data and do more advanced analysis at the station-level.

We'll use the function `import_stations()` for this task. The function is similar to `import_rides()` in two ways: it takes *ride-level data* as an input and scans a given directory for these bikeshare ride files. However, the output is station-level data. The function searches the ride-level data and returns a tibble of unique station.

In order for the function to work properly, we have to feed `import_stations()` the right information about our dataset. First, the function needs to know what columns to look for the station string data. for the `station_cols` argument, you can supply a tidyselect expression such as `tidyselect::contains("station")` . Similarly for `gps_cols`, supply an expression that finds the lat/long data. The `create_id` boolean argument tells the function whether or not to make a unique ID column.

```{r}
stations <- import_stations(eval_directory = data,
                            station_cols = tidyselect::contains("station"),
                            gps_cols = tidyselect::contains(c("lat", "lng")),
                            create_id = TRUE)
head(stations)
```

At this point, we could incorporate additional geolocation data to our station dictionary. But, let's skip that for now.

## Join Station and Ride Data 

The `rides` ride-level object is quite large, even in our reduced sample. We can reduce it's size by removing unnecessary columns and by using only a numeric station key to identify the start and end stations. Let's first drop unneeded columns. To keep things simple, let's only work with classic docked bikes and remove ride type

```{r}
classic <- rides %>%
  select(-c("bikeno", "ride_id",
            "start_lat", "start_lng", "end_lat","end_lng" ))%>%
  filter(rideable_type == "classic_bike") %>%
  select(-rideable_type)

head(classic)
```

Now, we see that the `start` and `end` are string values. But we don't always need to have the station name itself in the working dataset. We can further reduce the size by joining the ride data with the station data and keeping only the numeric `project_id` for each start and end station. Finally, let's simplify the member variable to be binary; we'll tell `clean_member()` what string values should be categorized under `TRUE` and `FALSE` .

```{r}
# make sure that station_no is saved as numeric
stations <- stations %>%
  mutate(station_no = as.numeric(station_no))


classic <- classic %>%
  left_join(stations, 
            by = c("start" = "station_name", "startno" = "station_no"),
            copy = FALSE) %>%
  rename("start_id_proj" = "id_proj") %>%
  select(-c(year, tidyselect::contains(c("lat", "lng")))) %>%
  left_join(stations, 
            by = c("end" = "station_name", "endno" = "station_no"),
            copy = FALSE) %>%
  rename("end_id_proj" = "id_proj") %>%
  select(-c(year, start, end, startno, endno, tidyselect::contains(c("lat", "lng")))) %>%
  clean_member(col = "member", 
               true = c("Member"), 
               false = c("guest", "Casual", "Unknown"))
  
```

## Transform to Origin-Destination

We could keep the data like this, but let's transform to origin-destination (more...)

Add hour, month, etc

```{r}
classic %>%
  transform_od(origin_datetime = startdt, destination_datetime = enddt,
               member_var = member)
```
